{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6452797,"sourceType":"datasetVersion","datasetId":3725555}],"dockerImageVersionId":30615,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/amaninaman/nyc-taxi-trip-records-with-gas-prices?scriptVersionId=155728701\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# MERGING NYC GAS PRICE DATA WITH NYC TAXI TRIP RECORDS DATA SET\nIn this notebook, I augment the analysis of NYC taxi trip records (Jan-Aug 2023) by integrating external data on weekly average motor gasoline prices from NYSERDA. After loading and exploring the main dataset, I scrape and process gas prices. The notebook then aligns trip data with gas prices based on pickup dates, addressing missing values through a fill strategy. Duplicate rows are removed, and a 'Gas Prices' column is added, representing gasoline prices in cents per gallon for each trip. The goal is to uncover correlations between taxi fares and gasoline prices, shedding light on potential patterns amid fuel cost fluctuations. Motivated by my observation that Uber prices were more affordable in Boston compared to Seattle, with a parallel difference in gas prices, I recognized the significance of considering fuel costs in such analyses. \n","metadata":{}},{"cell_type":"markdown","source":"![](https://i.postimg.cc/Kcgh5DKp/column.png)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-19T20:57:56.534318Z","iopub.execute_input":"2023-12-19T20:57:56.534771Z","iopub.status.idle":"2023-12-19T20:57:57.019725Z","shell.execute_reply.started":"2023-12-19T20:57:56.534732Z","shell.execute_reply":"2023-12-19T20:57:57.018452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/nyc-taxi-trip-records-from-jan-2023-to-jun-2023/nyc_yellow_taxi_trip_records_from_Jan_to_Aug_2023.csv')\ndf.head(35)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:57:57.021989Z","iopub.execute_input":"2023-12-19T20:57:57.022655Z","iopub.status.idle":"2023-12-19T20:59:46.193398Z","shell.execute_reply.started":"2023-12-19T20:57:57.022606Z","shell.execute_reply":"2023-12-19T20:59:46.191799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since it is going to take a lot of time to iterate 19,493,059 records, We will use random.sample() function to generate 1,000,000 unique index numbers to randomly select one million records from the dataframe. **If you are sure that your system can handle huge amount data you can skip the next three code blocks.**","metadata":{}},{"cell_type":"code","source":"import random\nrandom.seed(84)\nindex_list=random.sample(range(0, df.shape[0]), 1000000)\nprint(index_list[0:100])","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:59:46.195423Z","iopub.execute_input":"2023-12-19T20:59:46.196043Z","iopub.status.idle":"2023-12-19T20:59:47.428655Z","shell.execute_reply.started":"2023-12-19T20:59:46.196002Z","shell.execute_reply":"2023-12-19T20:59:47.42729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index_list=np.array(index_list)\nprint(index_list.shape)\nindex_list=np.sort(index_list)\nindex_list[0:100]","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:59:47.431499Z","iopub.execute_input":"2023-12-19T20:59:47.431955Z","iopub.status.idle":"2023-12-19T20:59:47.675669Z","shell.execute_reply.started":"2023-12-19T20:59:47.431914Z","shell.execute_reply":"2023-12-19T20:59:47.674169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=df.iloc[index_list].sort_index()\ndf.reset_index(inplace=True,drop=True)\ndf.head(35)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:59:47.677719Z","iopub.execute_input":"2023-12-19T20:59:47.679253Z","iopub.status.idle":"2023-12-19T20:59:48.764609Z","shell.execute_reply.started":"2023-12-19T20:59:47.679203Z","shell.execute_reply":"2023-12-19T20:59:48.763628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The range of dates we will deal with:","metadata":{}},{"cell_type":"code","source":"print(df[\"tpep_pickup_datetime\"].max())\nprint(df[\"tpep_pickup_datetime\"].min())","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:59:48.766294Z","iopub.execute_input":"2023-12-19T20:59:48.766982Z","iopub.status.idle":"2023-12-19T20:59:49.394064Z","shell.execute_reply.started":"2023-12-19T20:59:48.766943Z","shell.execute_reply":"2023-12-19T20:59:49.392735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*to_datetime()* function in Pandas will convert string values in pickup and dropoff columns into datetime64 datatype.","metadata":{}},{"cell_type":"code","source":"df[\"tpep_pickup_datetime\"]=pd.to_datetime(df[\"tpep_pickup_datetime\"])\ndf[\"tpep_dropoff_datetime\"]=pd.to_datetime(df[\"tpep_dropoff_datetime\"])\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:59:49.396142Z","iopub.execute_input":"2023-12-19T20:59:49.396751Z","iopub.status.idle":"2023-12-19T20:59:50.516997Z","shell.execute_reply.started":"2023-12-19T20:59:49.396708Z","shell.execute_reply":"2023-12-19T20:59:50.515371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this step,we will get the data from the New York State Energy Research and Development Authority (NYSERDA) website, specifically the page detailing weekly average motor gasoline prices. It uses the *requests* library to retrieve the HTML content from the specified URL. The *pd.read_html()* function from the pandas library is then employed to extract tables from the HTML content, and the resulting data is actually a set of dataframes stored in the gas_prices variable.\n\n","metadata":{}},{"cell_type":"code","source":"import requests\n\nurl = requests.get('https://www.nyserda.ny.gov/Energy-Prices/Motor-Gasoline/Weekly-Average-Motor-Gasoline-Prices')\ngas_prices=pd.read_html(url.text)\n\ngas_prices\n","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:59:50.518834Z","iopub.execute_input":"2023-12-19T20:59:50.51928Z","iopub.status.idle":"2023-12-19T20:59:51.606528Z","shell.execute_reply.started":"2023-12-19T20:59:50.519238Z","shell.execute_reply":"2023-12-19T20:59:51.605543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NY_gas_prices=gas_prices[1]","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:59:51.607878Z","iopub.execute_input":"2023-12-19T20:59:51.609007Z","iopub.status.idle":"2023-12-19T20:59:51.614354Z","shell.execute_reply.started":"2023-12-19T20:59:51.60897Z","shell.execute_reply":"2023-12-19T20:59:51.613319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NY_gas_prices.iloc[:,0]","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:59:51.618103Z","iopub.execute_input":"2023-12-19T20:59:51.618505Z","iopub.status.idle":"2023-12-19T20:59:51.632841Z","shell.execute_reply.started":"2023-12-19T20:59:51.618474Z","shell.execute_reply":"2023-12-19T20:59:51.631859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NY_gas_prices.iloc[:,1]","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:59:51.63422Z","iopub.execute_input":"2023-12-19T20:59:51.635089Z","iopub.status.idle":"2023-12-19T20:59:51.649472Z","shell.execute_reply.started":"2023-12-19T20:59:51.635029Z","shell.execute_reply":"2023-12-19T20:59:51.648021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will need first and second columns containing Date and Price(Current year) data.","metadata":{}},{"cell_type":"code","source":"NY_Dates_GasPrices=pd.concat([pd.to_datetime(NY_gas_prices.iloc[:,0]),NY_gas_prices.iloc[:,1]],axis=\"columns\")\nNY_Dates_GasPrices","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:59:51.651097Z","iopub.execute_input":"2023-12-19T20:59:51.651549Z","iopub.status.idle":"2023-12-19T20:59:51.676186Z","shell.execute_reply.started":"2023-12-19T20:59:51.651512Z","shell.execute_reply":"2023-12-19T20:59:51.675256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2023-06-30 23:59:49 -\n2023-01-01 00:00:52\n\nThese were the minimum and maximum values for the date column. To prepare this dataframe for matching the data on datetime values, we will filter the data to this range.","metadata":{}},{"cell_type":"code","source":"NY_Dates_GasPrices.columns=[\"Date\",\"Price\"]\nNY_Dates_GasPrices=NY_Dates_GasPrices[(NY_Dates_GasPrices['Date']>='2023-01-01') & (NY_Dates_GasPrices['Date']<='2023-07-01')]\nNY_Dates_GasPrices","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:59:51.677766Z","iopub.execute_input":"2023-12-19T20:59:51.678339Z","iopub.status.idle":"2023-12-19T20:59:51.698187Z","shell.execute_reply.started":"2023-12-19T20:59:51.6783Z","shell.execute_reply":"2023-12-19T20:59:51.696853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As it was stated, NY gas prices are showing the weekly average instead of daily prices.This code is calculating the number of days to be created first and then generating a numpy list called *date_list* by adding consecutive amount of days to the minimum date value. The idea is to create a seperate  dataframe based on days instead of weeks and then merge these records with *NY_Dates_GasPrices*.","metadata":{}},{"cell_type":"code","source":"import datetime as dt\n\nimport numpy as np\n\ndate_list=np.array([])\n\ndifference=pd.Series(df[\"tpep_pickup_datetime\"].max()-df[\"tpep_pickup_datetime\"].min())\nprint(difference.dt.days[0])\nprint(type(difference.dt.days[0]))\n\nfor i in range(0,difference.dt.days[0]+2):\n  date_item=(df[\"tpep_pickup_datetime\"].min())+(dt.timedelta(days=i))\n  date_list=np.append(date_list,date_item)\n\n\nprint(date_list)\nprint(type(date_list))\nprint(date_list.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:59:51.700161Z","iopub.execute_input":"2023-12-19T20:59:51.701391Z","iopub.status.idle":"2023-12-19T20:59:52.170428Z","shell.execute_reply.started":"2023-12-19T20:59:51.701337Z","shell.execute_reply":"2023-12-19T20:59:52.169111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's create a Price column with NaN values. After merging *date_list* and *NY_Dates_GasPrices* dataframes, we will fill the NaN values by using *fill_na* method of Pandas library.","metadata":{}},{"cell_type":"code","source":"NaN_col=pd.Series([np.NaN]*date_list.shape[0])\ndate_list=pd.concat([pd.Series(pd.to_datetime(date_list)),NaN_col],axis=\"columns\")\ndate_list","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:59:52.172026Z","iopub.execute_input":"2023-12-19T20:59:52.172495Z","iopub.status.idle":"2023-12-19T20:59:52.192158Z","shell.execute_reply.started":"2023-12-19T20:59:52.17246Z","shell.execute_reply":"2023-12-19T20:59:52.190701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NY_Dates_GasPrices.columns=[\"Date\",\"Price\"]\ndate_list.columns=[\"Date\",\"Price\"]\ndates_Merged=pd.concat([NY_Dates_GasPrices,date_list],axis=\"rows\", ignore_index=True)\ndates_Merged","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:59:52.194105Z","iopub.execute_input":"2023-12-19T20:59:52.194825Z","iopub.status.idle":"2023-12-19T20:59:52.216224Z","shell.execute_reply.started":"2023-12-19T20:59:52.194771Z","shell.execute_reply":"2023-12-19T20:59:52.214754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dates_Merged=dates_Merged.sort_values(by=['Date'],ignore_index=True)\ndates_Merged","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:59:52.217616Z","iopub.execute_input":"2023-12-19T20:59:52.218101Z","iopub.status.idle":"2023-12-19T20:59:52.236195Z","shell.execute_reply.started":"2023-12-19T20:59:52.218024Z","shell.execute_reply":"2023-12-19T20:59:52.23486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dates_Merged['Price'].isna().value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:59:52.237607Z","iopub.execute_input":"2023-12-19T20:59:52.238037Z","iopub.status.idle":"2023-12-19T20:59:52.25538Z","shell.execute_reply.started":"2023-12-19T20:59:52.237986Z","shell.execute_reply":"2023-12-19T20:59:52.253962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dates_Merged['Price'].fillna(method=\"ffill\",inplace=True)\ndates_Merged['Price'].fillna(method=\"bfill\",inplace=True)\ndates_Merged.head(35)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:59:52.256909Z","iopub.execute_input":"2023-12-19T20:59:52.258037Z","iopub.status.idle":"2023-12-19T20:59:52.278382Z","shell.execute_reply.started":"2023-12-19T20:59:52.258002Z","shell.execute_reply":"2023-12-19T20:59:52.276988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We should iterate the merged dataframe and detect the indexes of duplicating values.","metadata":{}},{"cell_type":"code","source":"import datetime as dt\n\nindexes_to_be_removed=np.array([],dtype=\"int32\")\n\nfor i in range(0,dates_Merged.shape[0]-1):\n    if dates_Merged.iloc[i,0].date()==dates_Merged.iloc[i+1,0].date():\n        indexes_to_be_removed=np.append(indexes_to_be_removed,i)\n\n    \n\nprint(indexes_to_be_removed)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:59:52.280201Z","iopub.execute_input":"2023-12-19T20:59:52.280839Z","iopub.status.idle":"2023-12-19T20:59:52.313295Z","shell.execute_reply.started":"2023-12-19T20:59:52.280802Z","shell.execute_reply":"2023-12-19T20:59:52.312008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dates_Merged.drop(labels=indexes_to_be_removed,axis=\"rows\",inplace=True)\ndates_Merged[0:35]","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:59:52.314547Z","iopub.execute_input":"2023-12-19T20:59:52.315553Z","iopub.status.idle":"2023-12-19T20:59:52.34068Z","shell.execute_reply.started":"2023-12-19T20:59:52.315516Z","shell.execute_reply":"2023-12-19T20:59:52.33922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dates_Merged.reset_index(inplace=True, drop=True)\ndates_Merged.head(35)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:59:52.343038Z","iopub.execute_input":"2023-12-19T20:59:52.344791Z","iopub.status.idle":"2023-12-19T20:59:52.365955Z","shell.execute_reply.started":"2023-12-19T20:59:52.34458Z","shell.execute_reply":"2023-12-19T20:59:52.364191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This code snippet iterates through the rows of df (taxi trip records) and dates_Merged to match and extract corresponding gasoline prices based on pickup dates. The nested loop efficiently populates the gas_Price_Column array with the associated prices. The use of clear_output provides a clean display, updating progress by printing the index of processed records at 1,000-record intervals. ","metadata":{}},{"cell_type":"code","source":"from IPython.display import clear_output\n\ngas_Price_Column=np.array([],dtype=\"float64\")\n\nfor item in df.itertuples():\n    for date_list_item in dates_Merged.itertuples():\n        if item.tpep_pickup_datetime.date()==date_list_item.Date.date():\n            matching_price=dates_Merged.loc[dates_Merged['Date'].dt.date==item.tpep_pickup_datetime.date(),'Price'].values\n            gas_Price_Column = np.append(gas_Price_Column, matching_price)\n    if item.Index%1000==0:\n        clear_output(wait=True)\n        print(str(item.Index)+ \" out of \"+str(df.shape[0])+' records processed.')\n        print(\"Completed : %\"+ str((item.Index /df.shape[0]) *100))","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:59:52.367938Z","iopub.execute_input":"2023-12-19T20:59:52.368376Z","iopub.status.idle":"2023-12-19T21:45:46.859768Z","shell.execute_reply.started":"2023-12-19T20:59:52.368337Z","shell.execute_reply":"2023-12-19T21:45:46.858657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Gas Prices']=gas_Price_Column # cents per gallon\n\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2023-12-19T21:45:46.861958Z","iopub.execute_input":"2023-12-19T21:45:46.862636Z","iopub.status.idle":"2023-12-19T21:45:46.962304Z","shell.execute_reply.started":"2023-12-19T21:45:46.862592Z","shell.execute_reply":"2023-12-19T21:45:46.961152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.plot(x=\"tpep_pickup_datetime\",y=\"Gas Prices\", kind=\"line\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-19T22:26:06.154313Z","iopub.execute_input":"2023-12-19T22:26:06.154772Z","iopub.status.idle":"2023-12-19T22:26:11.357561Z","shell.execute_reply.started":"2023-12-19T22:26:06.154736Z","shell.execute_reply":"2023-12-19T22:26:11.356249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title(\"Correlation between distance and tip amount\")\nplt.scatter(df['trip_distance'],df['tip_amount'])\n\nplt.xlim(0.0, 150.0)\nplt.xlabel(\"Trip Distance\")\n\nplt.ylim(0.0,200.0)\nplt.ylabel(\"Tip Amount\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-19T22:24:06.185832Z","iopub.execute_input":"2023-12-19T22:24:06.186293Z","iopub.status.idle":"2023-12-19T22:24:08.364636Z","shell.execute_reply.started":"2023-12-19T22:24:06.186258Z","shell.execute_reply":"2023-12-19T22:24:08.363376Z"},"trusted":true},"execution_count":null,"outputs":[]}]}